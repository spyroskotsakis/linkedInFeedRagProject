# ğŸ”§ Scripts & Tools Reference

**Complete documentation for all scripts, tools, and utilities in the LinkedIn Feed RAG Project**

## ğŸ“‹ **Table of Contents**

1. [Setup & Configuration Scripts](#-setup--configuration-scripts)
2. [Testing & Debugging Scripts](#-testing--debugging-scripts)
3. [Development Scripts](#-development-scripts)
4. [Production Scripts](#-production-scripts)
5. [Utility Scripts](#-utility-scripts)
6. [Command Reference](#-command-reference)

---

## ğŸ› ï¸ **Setup & Configuration Scripts**

### **`setup_env.py` - Environment Configuration**

**Purpose**: Interactive environment setup for the RAG system

**Usage**:
```bash
python setup_env.py
```

**What it does**:
- Prompts for LLM provider preference (Ollama/Azure)
- Configures model settings and parameters
- Sets up API endpoints and URLs
- Creates `.env` file with all required variables
- Validates configuration completeness

**Interactive Prompts**:
```
ğŸ¤– LLM Provider Configuration
Choose LLM provider (ollama/azure) [ollama]: 
Ollama model name [mistral-nemo:12b]: 
Temperature for LLM (0.0-1.0) [0.1]: 
Max tokens for responses [2048]: 
```

**Output**:
- Creates `.env` file with complete configuration
- Validates all required variables are present
- Provides setup confirmation

**Example Output**:
```
âœ… Environment file created successfully!
ğŸ“‹ Configuration Summary:
   â€¢ LLM Provider: ollama
   â€¢ Model: mistral-nemo:12b
   â€¢ Temperature: 0.1
   â€¢ Max Tokens: 2048
   â€¢ API URL: http://localhost:8000

ğŸš€ Next Steps:
   1. Start Ollama: ollama serve
   2. Pull model: ollama pull mistral-nemo:12b
   3. Verify setup: python verify_rag_env.py
```

---

### **`verify_rag_env.py` - Environment Verification**

**Purpose**: Comprehensive verification of RAG system environment

**Usage**:
```bash
python verify_rag_env.py
```

**What it checks**:
- `.env` file existence and content
- Required environment variables
- Docker files availability
- RAG components presence
- Data directory structure
- Ollama connection status

**Verification Categories**:

#### **Environment File Check**
```bash
âœ… .env file found
âœ… Loaded 33 environment variables
```

#### **Required Variables Check**
```bash
âœ… RAG_API_URL: http://localhost:8000
âœ… RAG_LLM_PROVIDER: ollama
âœ… RAG_EMBEDDING_MODEL: all-MiniLM-L6-v2
âœ… RAG_VECTOR_STORE_PATH: /app/vector_store
âœ… RAG_LLM_TEMPERATURE: 0.1
âœ… RAG_LLM_MAX_TOKENS: 2048
```

#### **LLM Configuration Check**
```bash
ğŸ¤– Ollama Configuration:
   âœ… OLLAMA_BASE_URL: http://host.docker.internal:11434
   âœ… OLLAMA_MODEL: mistral-nemo:12b
```

#### **Docker Configuration Check**
```bash
ğŸ³ Docker Configuration:
   âœ… Docker Compose configuration
   âœ… RAG API Dockerfile
   âœ… Streamlit UI Dockerfile
```

#### **RAG Components Check**
```bash
ğŸ”§ RAG Components:
   âœ… RAG API main file
   âœ… RAG package init
   âœ… RAG core package
   âœ… RAG configuration
   âœ… RAG manager
   âœ… Health API
```

#### **Data Directory Check**
```bash
ğŸ“ Data Directory:
   âœ… Data directory exists: data
   âœ… Found 1 data export directories
      â€¢ posts_37_fast_fast_2025-07-25_22-45
```

#### **Ollama Connection Check**
```bash
ğŸ”— Ollama Connection:
   âœ… Ollama is running
   âœ… Available models: mistral-nemo:latest, codellama:34b, ...
```

**Example Complete Output**:
```
============================================================
ğŸ” RAG Environment Verification
============================================================

âœ… .env file found
âœ… Loaded 33 environment variables

ğŸ“‹ Required Environment Variables:
âœ… RAG_API_URL: http://localhost:8000
âœ… RAG_LLM_PROVIDER: ollama
âœ… RAG_EMBEDDING_MODEL: all-MiniLM-L6-v2
âœ… RAG_VECTOR_STORE_PATH: /app/vector_store
âœ… RAG_LLM_TEMPERATURE: 0.1
âœ… RAG_LLM_MAX_TOKENS: 2048

ğŸ¤– Ollama Configuration:
   âœ… OLLAMA_BASE_URL: http://host.docker.internal:11434
   âœ… OLLAMA_MODEL: mistral-nemo:12b

ğŸ³ Docker Configuration:
   âœ… Docker Compose configuration
   âœ… RAG API Dockerfile
   âœ… Streamlit UI Dockerfile

ğŸ”§ RAG Components:
   âœ… RAG API main file
   âœ… RAG package init
   âœ… RAG core package
   âœ… RAG configuration
   âœ… RAG manager
   âœ… Health API

ğŸ“ Data Directory:
   âœ… Data directory exists: data
   âœ… Found 1 data export directories
      â€¢ posts_37_fast_fast_2025-07-25_22-45

ğŸ”— Ollama Connection:
   âœ… Ollama is running
   âœ… Available models: mistral-nemo:latest, codellama:34b, ...

============================================================
ğŸ“Š Verification Summary:
============================================================
   âœ… PASS Environment File
   âœ… PASS Required Variables
   âœ… PASS LLM Configuration
   âœ… PASS Docker Files
   âœ… PASS RAG Components
   âœ… PASS Data Directory
   âœ… PASS Ollama Connection

ğŸ‰ All checks passed! Your RAG environment is ready.

ğŸš€ Next Steps:
   1. Start the system: ./start_production.sh
   2. Access the UI: http://localhost:8501
   3. Access the API: http://localhost:8000
```

---

## ğŸ§ª **Testing & Debugging Scripts**

### **`debug_rag_system.py` - RAG System Testing**

**Purpose**: Comprehensive testing of RAG system components

**Usage**:
```bash
python debug_rag_system.py
```

**What it tests**:
- API health endpoints
- Data loading from files
- Vector indexing process
- RAG query functionality
- Collection management
- System performance

**Test Categories**:

#### **1. API Health Test**
```bash
ğŸ” Testing RAG API Health...
âœ… Health Check: {
  "status": "healthy",
  "components": {
    "rag_manager": {"status": "healthy", "details": {...}},
    "system_ready": {"status": "healthy", "ready": true}
  },
  "timestamp": "2025-07-26T07:10:29.640900"
}
```

#### **2. API Ready Test**
```bash
ğŸ” Testing RAG API Ready...
âœ… Ready Check: {"status": "ready"}
```

#### **3. Data Loading Test**
```bash
ğŸ” Testing Data Loading...
ğŸ“ Using data directory: data/posts_37_fast_fast_2025-07-25_22-45
ğŸ“„ Using JSON file: data/posts_37_fast_fast_2025-07-25_22-45/linkedin_feed_fast_fast_20250725_224507.json
âœ… Loaded 37 posts from JSON

ğŸ“Š Content samples (first 10 posts):
  1. ğŸ”´ ğŸ‰ sourcelair mafia on #mikrikouventa ğŸ‰ ğŸ¥
  2. download our free ebook to discover how agentic ai can transform...
  3. damnnâ€¦ openai, google & anthropic just dropped their internal ai playbooks...
  ...

ğŸ¯ Found 4 posts mentioning OpenAI:
  Post 3: damnnâ€¦ openai, google & anthropic just dropped their internal ai playbooks...
  Post 6: testing chatgpt vs photoshop for photo editing led to some surprising results...
  Post 8: how to build an ai agent using n8n...
  Post 10: this is the best video i've seen about llms in 2025...
```

#### **4. Collections Test**
```bash
ğŸ” Testing Collections...
âœ… Collections: {"collections": ["linkedin_posts"]}
```

#### **5. Data Indexing Test**
```bash
ğŸ” Testing Data Indexing...
ğŸ“¤ Sending indexing request: {
  "data_path": "data/posts_37_fast_fast_2025-07-25_22-45",
  "collection_name": "test_collection"
}
âœ… Indexing Response: {
  "message": "Indexing started",
  "data_path": "data/posts_37_fast_fast_2025-07-25_22-45",
  "collection": "test_collection"
}
```

#### **6. Collection Stats Test**
```bash
ğŸ” Testing Collection Stats for 'test_collection'...
âœ… Collection Stats: {
  "collection": "test_collection",
  "stats": {
    "collection_name": "test_collection",
    "document_count": 100,
    "embedding_dimension": 384,
    "index_type": "hnsw"
  }
}
```

#### **7. RAG Query Test**
```bash
ğŸ” Testing RAG Query: 'find me posts about openAI'
ğŸ“¤ Sending query request: {
  "query": "find me posts about openAI",
  "collection_name": "test_collection",
  "max_results": 5
}
âœ… Query Response: {
  "query": "find me posts about openAI",
  "answer": "Based on the provided context, here's what I found: ...",
  "sources": [
    {
      "content": "Check out & follow the new official LinkedIn page for OpenAI...",
      "metadata": {...},
      "similarity_score": 0.5439465641975403
    },
    ...
  ],
  "metadata": {...}
}
```

**Complete Test Summary**:
```
============================================================
ğŸ“Š TEST SUMMARY
============================================================
âœ… API Health: PASSED
âœ… API Ready: PASSED
âœ… Data Loading: PASSED
âœ… Collections: PASSED
âœ… Data Indexing: PASSED
âœ… Collection Stats: PASSED
âœ… RAG Query: PASSED

ğŸ” Query Analysis for 'find me posts about openAI':
ğŸ“ Answer: Based on the provided context, here's what I found: ...
ğŸ“š Sources: 5 found
  Source 1: Check out & follow the new official LinkedIn page for OpenAI...
  Source 2: damnnâ€¦ OpenAI, Google & Anthropic just dropped their internal AI playbooks...
  Source 3: How to build an AI agent using n8n...
  ...
```

---

### **`simple_linkedin_test.py` - LinkedIn Connection Test**

**Purpose**: Basic LinkedIn connectivity and credential testing

**Usage**:
```bash
python simple_linkedin_test.py
```

**What it tests**:
- Credential validity
- Network connectivity
- Login success
- Basic scraping capability

**Test Process**:
```bash
ğŸ” Testing LinkedIn Connection...
ğŸ“‹ Loading credentials from .env file
ğŸŒ Testing network connectivity
ğŸ” Attempting LinkedIn login
âœ… Login successful
ğŸ“Š Testing basic scraping capability
âœ… Scraping test successful
```

**Example Output**:
```
============================================================
ğŸ” LinkedIn Connection Test
============================================================

ğŸ“‹ Credentials loaded successfully
ğŸŒ Network connectivity: OK
ğŸ” LinkedIn login: SUCCESS
ğŸ“Š Basic scraping test: PASSED

âœ… All tests passed! LinkedIn connection is working.
```

---

### **`test_linkedin_connection.py` - Advanced Connection Test**

**Purpose**: Comprehensive LinkedIn connection and scraping testing

**Usage**:
```bash
python test_linkedin_connection.py
```

**What it tests**:
- Authentication flow
- Session management
- Rate limiting
- Error handling
- Advanced scraping features

**Advanced Test Features**:
```bash
ğŸ” Advanced LinkedIn Connection Test
============================================================

ğŸ“‹ Authentication Flow Test:
âœ… Credential validation
âœ… Login process
âœ… Session creation
âœ… Cookie management

ğŸŒ Network & Session Test:
âœ… Connection stability
âœ… Session persistence
âœ… Rate limit detection
âœ… Error recovery

ğŸ“Š Scraping Capability Test:
âœ… Basic post extraction
âœ… Engagement data parsing
âœ… Author information
âœ… Timestamp handling

ğŸ”§ Error Handling Test:
âœ… Network timeout handling
âœ… Authentication failure recovery
âœ… Rate limit handling
âœ… Invalid data handling
```

---

## ğŸ”§ **Development Scripts**

### **`setup_credentials.py` - Credential Setup**

**Purpose**: Secure LinkedIn credential configuration

**Usage**:
```bash
python setup_credentials.py
```

**Interactive Setup**:
```bash
============================================================
ğŸ” LinkedIn Credential Setup
============================================================

ğŸ“§ LinkedIn Email: your-email@example.com
ğŸ”‘ LinkedIn Password: ********
âœ… Credentials saved securely

ğŸš€ Next Steps:
   1. Test connection: python simple_linkedin_test.py
   2. Start scraping: python complete_linkedin_scraper.py
```

**Security Features**:
- Encrypted credential storage
- Environment variable configuration
- Secure file permissions
- Validation and testing

---

### **`setup_conda_env.sh` - Conda Environment Setup**

**Purpose**: Complete development environment setup

**Usage**:
```bash
./setup_conda_env.sh
```

**What it creates**:
- Conda environment: `linkedin-feed-capture`
- Installs all dependencies
- Configures Python path
- Sets up development tools

**Setup Process**:
```bash
ğŸš€ Setting up Conda Environment...
ğŸ“¦ Creating environment: linkedin-feed-capture
ğŸ”§ Installing dependencies...
âœ… Environment setup complete

ğŸ¯ Next Steps:
   1. Activate environment: conda activate linkedin-feed-capture
   2. Verify installation: python verify_env.py
   3. Start development: python complete_linkedin_scraper.py
```

---

## ğŸš€ **Production Scripts**

### **`start_production.sh` - Automated Production Startup**

**Purpose**: Complete production system initialization

**Usage**:
```bash
./start_production.sh
```

**What it does**:
- Checks Docker and Docker Compose
- Verifies Ollama installation and models
- Creates data directory if needed
- Sets up environment file
- Builds and starts Docker services
- Performs health checks
- Shows access information

**Complete Process**:
```bash
ğŸš€ LinkedIn Feed Explorer - Production Start Script
==================================================

[INFO] Checking Docker...
[SUCCESS] Docker is running

[INFO] Checking Docker Compose...
[SUCCESS] Docker Compose is available

[INFO] Checking Ollama...
[SUCCESS] Ollama is running

[INFO] Checking Ollama model...
[SUCCESS] Model mistral-nemo:12b is available

[INFO] Checking data directory...
[SUCCESS] Data directory exists

[INFO] Checking environment configuration...
[SUCCESS] Environment file exists

[INFO] Building and starting services...
[INFO] Building Docker images...
[INFO] Starting services...
[INFO] Waiting for services to be ready...
[INFO] Checking service health...
[SUCCESS] RAG API is healthy
[SUCCESS] Streamlit UI is healthy

ğŸ‰ LinkedIn Feed Explorer is now running!

ğŸ“± Access Points:
   â€¢ Streamlit UI: http://localhost:8501
   â€¢ RAG API: http://localhost:8000
   â€¢ API Documentation: http://localhost:8000/docs

ğŸ”§ Management Commands:
   â€¢ View logs: docker-compose logs -f
   â€¢ Stop services: docker-compose down
   â€¢ Restart services: docker-compose restart
   â€¢ Check status: docker-compose ps

ğŸ“š Documentation:
   â€¢ Production Guide: PRODUCTION_DEPLOYMENT.md
```

---

## ğŸ› ï¸ **Utility Scripts**

### **`verify_env.py` - Environment Verification**

**Purpose**: Basic environment verification for development

**Usage**:
```bash
python verify_env.py
```

**What it checks**:
- Python environment
- Required packages
- Basic configuration
- Development tools

---

### **`demo.py` - Demo Application**

**Purpose**: Demonstration of core functionality

**Usage**:
```bash
python demo.py
```

**Features**:
- Basic scraping demonstration
- Data processing examples
- Export functionality
- Performance metrics

---

### **`example.py` - Code Examples**

**Purpose**: Example code snippets and usage patterns

**Usage**:
```bash
python example.py
```

**Examples**:
- Basic scraping setup
- Data processing patterns
- API integration
- Custom configurations

---

## ğŸ“‹ **Command Reference**

### **Quick Commands**

#### **Setup Commands**
```bash
# Environment setup
python setup_env.py                    # Interactive environment setup
python verify_rag_env.py               # Verify RAG environment
./setup_conda_env.sh                   # Setup conda environment
python setup_credentials.py            # Setup LinkedIn credentials
```

#### **Testing Commands**
```bash
# System testing
python debug_rag_system.py             # Comprehensive RAG testing
python simple_linkedin_test.py         # LinkedIn connection test
python test_linkedin_connection.py     # Advanced LinkedIn testing
python verify_env.py                   # Basic environment verification
```

#### **Production Commands**
```bash
# Production management
./start_production.sh                  # Start production system
docker-compose up -d                   # Start services
docker-compose down                    # Stop services
docker-compose logs -f                 # View logs
docker-compose ps                      # Check status
```

#### **Scraping Commands**
```bash
# LinkedIn scraping
python complete_linkedin_scraper_enhanced_fast.py --posts 100
python complete_linkedin_scraper.py --posts 50
python complete_linkedin_scraper.py --posts 5 --no-headless --verbose
```

### **Advanced Commands**

#### **Development Commands**
```bash
# Development setup
conda activate linkedin-feed-capture
pip install -r requirements.txt
pip install -e .

# Code quality
ruff check .
ruff format .
mypy .
pytest tests/ -v
```

#### **Debugging Commands**
```bash
# Service debugging
docker-compose logs rag-api
docker-compose logs streamlit-ui
docker-compose restart rag-api

# System debugging
curl http://localhost:8000/health
curl http://localhost:8501/_stcore/health
ollama list
```

#### **Data Management Commands**
```bash
# Data operations
ls -la data/
chmod -R 755 data/
python debug_rag_system.py

# API operations
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"query": "test query", "collection_name": "linkedin_posts"}'
```

### **Troubleshooting Commands**

#### **Common Issues**
```bash
# Port conflicts
lsof -i :8000
lsof -i :8501
kill -9 <PID>

# Permission issues
sudo chown -R $USER:$USER ./data
chmod +x *.sh

# Service issues
docker-compose down
docker-compose up --build
```

#### **Health Checks**
```bash
# Quick health check
curl http://localhost:8000/health
curl http://localhost:8000/ready
curl http://localhost:8501/_stcore/health

# Comprehensive health check
python verify_rag_env.py
python debug_rag_system.py
```

---

## ğŸ“Š **Script Output Examples**

### **Successful Setup Output**
```
============================================================
ğŸš€ LinkedIn Feed Explorer - Environment Setup
============================================================

ğŸ“‹ Let's configure your RAG system environment...

ğŸ¤– LLM Provider Configuration
Choose LLM provider (ollama/azure) [ollama]: ollama
Ollama model name [mistral-nemo:12b]: mistral-nemo:12b
Temperature for LLM (0.0-1.0) [0.1]: 0.1
Max tokens for responses [2048]: 2048

âœ… Environment file created successfully!
ğŸ“‹ Configuration Summary:
   â€¢ LLM Provider: ollama
   â€¢ Model: mistral-nemo:12b
   â€¢ Temperature: 0.1
   â€¢ Max Tokens: 2048
   â€¢ API URL: http://localhost:8000

ğŸš€ Next Steps:
   1. Start Ollama: ollama serve
   2. Pull model: ollama pull mistral-nemo:12b
   3. Verify setup: python verify_rag_env.py
```

### **Successful Testing Output**
```
ğŸš€ Starting Comprehensive RAG System Debug Test
============================================================

1ï¸âƒ£ Testing API Health...
âœ… Health Check: {"status": "healthy", ...}

2ï¸âƒ£ Testing API Ready...
âœ… Ready Check: {"status": "ready"}

3ï¸âƒ£ Testing Data Loading...
âœ… Loaded 37 posts from JSON

4ï¸âƒ£ Testing Collections...
âœ… Collections: {"collections": ["linkedin_posts"]}

5ï¸âƒ£ Testing Data Indexing...
âœ… Indexing Response: {"message": "Indexing started", ...}

6ï¸âƒ£ Testing Collection Stats...
âœ… Collection Stats: {"collection": "test_collection", ...}

7ï¸âƒ£ Testing RAG Query...
âœ… Query Response: {"query": "find me posts about openAI", ...}

============================================================
ğŸ“Š TEST SUMMARY
============================================================
âœ… Passed: 7/7
âŒ Failed: 0/7

ğŸ‰ ALL TESTS PASSED! RAG system is working correctly.
```

---

## ğŸ¯ **Best Practices**

### **Script Usage Guidelines**

1. **Always verify environment first**:
   ```bash
   python verify_rag_env.py
   ```

2. **Test before production**:
   ```bash
   python debug_rag_system.py
   ```

3. **Use automated startup**:
   ```bash
   ./start_production.sh
   ```

4. **Monitor logs regularly**:
   ```bash
   docker-compose logs -f
   ```

5. **Check health endpoints**:
   ```bash
   curl http://localhost:8000/health
   ```

### **Troubleshooting Workflow**

1. **Check environment**: `python verify_rag_env.py`
2. **Test RAG system**: `python debug_rag_system.py`
3. **Check services**: `docker-compose ps`
4. **View logs**: `docker-compose logs -f`
5. **Restart if needed**: `docker-compose restart`

### **Development Workflow**

1. **Setup environment**: `./setup_conda_env.sh`
2. **Configure credentials**: `python setup_credentials.py`
3. **Test connection**: `python simple_linkedin_test.py`
4. **Start development**: `python complete_linkedin_scraper.py`

---

**All scripts are documented and ready for use!** ğŸš€ğŸ“ŠğŸ”§ 