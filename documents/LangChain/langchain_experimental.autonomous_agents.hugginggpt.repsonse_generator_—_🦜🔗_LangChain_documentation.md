# langchain_experimental.autonomous_agents.hugginggpt.repsonse_generator â€” ðŸ¦œðŸ”— LangChain  documentation

**URL:** https://python.langchain.com/api_reference/_modules/langchain_experimental/autonomous_agents/hugginggpt/repsonse_generator.html
**Word Count:** 45
**Links Count:** 18
**Scraped:** 2025-07-21 09:19:27
**Status:** completed

---

# Source code for langchain\_experimental.autonomous\_agents.hugginggpt.repsonse\_generator               from typing import Any, List, Optional          from langchain.base_language import BaseLanguageModel     from langchain.chains import LLMChain     from langchain_core.callbacks.manager import Callbacks     from langchain_core.prompts import PromptTemplate                              [[docs]](https://python.langchain.com/api_reference/experimental/autonomous_agents/langchain_experimental.autonomous_agents.hugginggpt.repsonse_generator.ResponseGenerationChain.html#langchain_experimental.autonomous_agents.hugginggpt.repsonse_generator.ResponseGenerationChain)     class ResponseGenerationChain(LLMChain):         """Chain to execute tasks."""                         [[docs]](https://python.langchain.com/api_reference/experimental/autonomous_agents/langchain_experimental.autonomous_agents.hugginggpt.repsonse_generator.ResponseGenerationChain.html#langchain_experimental.autonomous_agents.hugginggpt.repsonse_generator.ResponseGenerationChain.from_llm)         @classmethod         def from_llm(cls, llm: BaseLanguageModel, verbose: bool = True) -> LLMChain:             execution_template = (                 "The AI assistant has parsed the user input into several tasks"                 "and executed them. The results are as follows:\n"                 "{task_execution}"                 "\nPlease summarize the results and generate a response."             )             prompt = PromptTemplate(                 template=execution_template,                 input_variables=["task_execution"],             )             return cls(prompt=prompt, llm=llm, verbose=verbose)                                                            [[docs]](https://python.langchain.com/api_reference/experimental/autonomous_agents/langchain_experimental.autonomous_agents.hugginggpt.repsonse_generator.ResponseGenerator.html#langchain_experimental.autonomous_agents.hugginggpt.repsonse_generator.ResponseGenerator)     class ResponseGenerator:         """Generates a response based on the input."""                         [[docs]](https://python.langchain.com/api_reference/experimental/autonomous_agents/langchain_experimental.autonomous_agents.hugginggpt.repsonse_generator.ResponseGenerator.html#langchain_experimental.autonomous_agents.hugginggpt.repsonse_generator.ResponseGenerator.__init__)         def __init__(self, llm_chain: LLMChain, stop: Optional[List] = None):             self.llm_chain = llm_chain             self.stop = stop                                        [[docs]](https://python.langchain.com/api_reference/experimental/autonomous_agents/langchain_experimental.autonomous_agents.hugginggpt.repsonse_generator.ResponseGenerator.html#langchain_experimental.autonomous_agents.hugginggpt.repsonse_generator.ResponseGenerator.generate)         def generate(self, inputs: dict, callbacks: Callbacks = None, **kwargs: Any) -> str:             """Given input, decided what to do."""             llm_response = self.llm_chain.run(**inputs, stop=self.stop, callbacks=callbacks)             return llm_response                                                            [[docs]](https://python.langchain.com/api_reference/experimental/autonomous_agents/langchain_experimental.autonomous_agents.hugginggpt.repsonse_generator.load_response_generator.html#langchain_experimental.autonomous_agents.hugginggpt.repsonse_generator.load_response_generator)     def load_response_generator(llm: BaseLanguageModel) -> ResponseGenerator:         """Load the ResponseGenerator."""              llm_chain = ResponseGenerationChain.from_llm(llm)         return ResponseGenerator(             llm_chain=llm_chain,         )