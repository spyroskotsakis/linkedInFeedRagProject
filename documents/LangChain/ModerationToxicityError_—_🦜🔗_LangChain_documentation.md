# ModerationToxicityError â€” ðŸ¦œðŸ”— LangChain  documentation

**URL:** https://python.langchain.com/api_reference/experimental/comprehend_moderation/langchain_experimental.comprehend_moderation.base_moderation_exceptions.ModerationToxicityError.html
**Word Count:** 13
**Links Count:** 107
**Scraped:** 2025-07-21 08:25:17
**Status:** completed

---

# ModerationToxicityError\#

_class _langchain\_experimental.comprehend\_moderation.base\_moderation\_exceptions.ModerationToxicityError\(

    _message : str = 'The prompt contains toxic content and cannot be processed'_, \)[\[source\]](https://python.langchain.com/api_reference/_modules/langchain_experimental/comprehend_moderation/base_moderation_exceptions.html#ModerationToxicityError)\#     

Exception raised if Toxic entities are detected.

Parameters:     

**message** \(_str_\)

message \-- explanation of the error     

__On this page