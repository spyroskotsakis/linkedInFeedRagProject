# WhyLabsCallbackHandler â€” ðŸ¦œðŸ”— LangChain  documentation

**URL:** https://python.langchain.com/api_reference/community/callbacks/langchain_community.callbacks.whylabs_callback.WhyLabsCallbackHandler.html
**Word Count:** 1498
**Links Count:** 273
**Scraped:** 2025-07-21 08:16:51
**Status:** completed

---

# WhyLabsCallbackHandler\#

_class _langchain\_community.callbacks.whylabs\_callback.WhyLabsCallbackHandler\(_logger : Logger_, _handler : Any_\)[\[source\]](https://python.langchain.com/api_reference/_modules/langchain_community/callbacks/whylabs_callback.html#WhyLabsCallbackHandler)\#     

Callback Handler for logging to WhyLabs. This callback handler utilizes langkit to extract features from the prompts & responses when interacting with an LLM. These features can be used to guardrail, evaluate, and observe interactions over time to detect issues relating to hallucinations, prompt engineering, or output validation. LangKit is an LLM monitoring toolkit developed by WhyLabs.

Here are some examples of what can be monitored with LangKit: \* Text Quality

>   * readability score >  >   * complexity and grade scores >  > 

  * Text Relevance \- Similarity scores between prompt/responses \- Similarity scores against user-defined themes \- Topic classification

  * Security and Privacy \- patterns - count of strings matching a user-defined regex pattern group \- jailbreaks - similarity scores with respect to known jailbreak attempts \- prompt injection - similarity scores with respect to known prompt attacks \- refusals - similarity scores with respect to known LLM refusal responses

  * Sentiment and Toxicity \- sentiment analysis \- toxicity analysis

For more information, see <https://docs.whylabs.ai/docs/language-model-monitoring> or check out the LangKit repo here: [whylabs/langkit](https://github.com/whylabs/langkit)

â€” :param api\_key: WhyLabs API key. Optional because the preferred

> way to specify the API key is with environment variable WHYLABS\_API\_KEY.

Parameters:     

  * **org\_id** \(_Optional_ _\[__str_ _\]_\) â€“ WhyLabs organization id to write profiles to. Optional because the preferred way to specify the organization id is with environment variable WHYLABS\_DEFAULT\_ORG\_ID.

  * **dataset\_id** \(_Optional_ _\[__str_ _\]_\) â€“ WhyLabs dataset id to write profiles to. Optional because the preferred way to specify the dataset id is with environment variable WHYLABS\_DEFAULT\_DATASET\_ID.

  * **sentiment** \(_bool_\) â€“ Whether to enable sentiment analysis. Defaults to False.

  * **toxicity** \(_bool_\) â€“ Whether to enable toxicity analysis. Defaults to False.

  * **themes** \(_bool_\) â€“ Whether to enable theme analysis. Defaults to False.

  * **logger** \(_Logger_\)

  * **handler** \(_Any_\)

Initiate the rolling logger.

Attributes

`ignore_agent` | Whether to ignore agent callbacks.   ---|---   `ignore_chain` | Whether to ignore chain callbacks.   `ignore_chat_model` | Whether to ignore chat model callbacks.   `ignore_custom_event` | Ignore custom event.   `ignore_llm` | Whether to ignore LLM callbacks.   `ignore_retriever` | Whether to ignore retriever callbacks.   `ignore_retry` | Whether to ignore retry callbacks.   `raise_error` | Whether to raise an error if an exception occurs.   `run_inline` | Whether to run the callback inline.      Methods

`__init__`\(logger, handler\) | Initiate the rolling logger.   ---|---   `close`\(\) | Close any loggers to allow writing out of any profiles before exiting.   `flush`\(\) | Explicitly write current profile if using a rolling logger.   `from_params`\(\*\[, api\_key, org\_id, ...\]\) | Instantiate whylogs Logger from params.   `on_agent_action`\(action, \*, run\_id\[, ...\]\) | Run on agent action.   `on_agent_finish`\(finish, \*, run\_id\[, ...\]\) | Run on the agent end.   `on_chain_end`\(outputs, \*, run\_id\[, parent\_run\_id\]\) | Run when chain ends running.   `on_chain_error`\(error, \*, run\_id\[, parent\_run\_id\]\) | Run when chain errors.   `on_chain_start`\(serialized, inputs, \*, run\_id\) | Run when a chain starts running.   `on_chat_model_start`\(serialized, messages, \*, ...\) | Run when a chat model starts running.   `on_custom_event`\(name, data, \*, run\_id\[, ...\]\) | Override to define a handler for a custom event.   `on_llm_end`\(response, \*, run\_id\[, parent\_run\_id\]\) | Run when LLM ends running.   `on_llm_error`\(error, \*, run\_id\[, parent\_run\_id\]\) | Run when LLM errors.   `on_llm_new_token`\(token, \*\[, chunk, ...\]\) | Run on new LLM token.   `on_llm_start`\(serialized, prompts, \*, run\_id\) | Run when LLM starts running.   `on_retriever_end`\(documents, \*, run\_id\[, ...\]\) | Run when Retriever ends running.   `on_retriever_error`\(error, \*, run\_id\[, ...\]\) | Run when Retriever errors.   `on_retriever_start`\(serialized, query, \*, run\_id\) | Run when the Retriever starts running.   `on_retry`\(retry\_state, \*, run\_id\[, parent\_run\_id\]\) | Run on a retry event.   `on_text`\(text, \*, run\_id\[, parent\_run\_id\]\) | Run on an arbitrary text.   `on_tool_end`\(output, \*, run\_id\[, parent\_run\_id\]\) | Run when the tool ends running.   `on_tool_error`\(error, \*, run\_id\[, parent\_run\_id\]\) | Run when tool errors.   `on_tool_start`\(serialized, input\_str, \*, run\_id\) | Run when the tool starts running.      \_\_init\_\_\(

    _logger : Logger_,     _handler : Any_, \)[\[source\]](https://python.langchain.com/api_reference/_modules/langchain_community/callbacks/whylabs_callback.html#WhyLabsCallbackHandler.__init__)\#     

Initiate the rolling logger.

Parameters:     

  * **logger** \(_Logger_\)

  * **handler** \(_Any_\)

close\(\) â†’ None[\[source\]](https://python.langchain.com/api_reference/_modules/langchain_community/callbacks/whylabs_callback.html#WhyLabsCallbackHandler.close)\#     

Close any loggers to allow writing out of any profiles before exiting.

Return type:     

None

flush\(\) â†’ None[\[source\]](https://python.langchain.com/api_reference/_modules/langchain_community/callbacks/whylabs_callback.html#WhyLabsCallbackHandler.flush)\#     

Explicitly write current profile if using a rolling logger.

Return type:     

None

_classmethod _from\_params\(

    _\*_ ,     _api\_key : str | None = None_,     _org\_id : str | None = None_,     _dataset\_id : str | None = None_,     _sentiment : bool = False_,     _toxicity : bool = False_,     _themes : bool = False_,     _logger : Logger | None = None_, \) â†’ WhyLabsCallbackHandler[\[source\]](https://python.langchain.com/api_reference/_modules/langchain_community/callbacks/whylabs_callback.html#WhyLabsCallbackHandler.from_params)\#     

Instantiate whylogs Logger from params.

Parameters:     

  * **api\_key** \(_Optional_ _\[__str_ _\]_\) â€“ WhyLabs API key. Optional because the preferred way to specify the API key is with environment variable WHYLABS\_API\_KEY.

  * **org\_id** \(_Optional_ _\[__str_ _\]_\) â€“ WhyLabs organization id to write profiles to. If not set must be specified in environment variable WHYLABS\_DEFAULT\_ORG\_ID.

  * **dataset\_id** \(_Optional_ _\[__str_ _\]_\) â€“ The model or dataset this callback is gathering telemetry for. If not set must be specified in environment variable WHYLABS\_DEFAULT\_DATASET\_ID.

  * **sentiment** \(_bool_\) â€“ If True will initialize a model to perform sentiment analysis compound score. Defaults to False and will not gather this metric.

  * **toxicity** \(_bool_\) â€“ If True will initialize a model to score toxicity. Defaults to False and will not gather this metric.

  * **themes** \(_bool_\) â€“ If True will initialize a model to calculate distance to configured themes. Defaults to None and will not gather this metric.

  * **logger** \(_Optional_ _\[__Logger_ _\]_\) â€“ If specified will bind the configured logger as the telemetry gathering agent. Defaults to LangKit schema with periodic WhyLabs writer.

Return type:     

WhyLabsCallbackHandler

on\_agent\_action\(

    _action : [AgentAction](https://python.langchain.com/api_reference/core/agents/langchain_core.agents.AgentAction.html#langchain_core.agents.AgentAction "langchain_core.agents.AgentAction")_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run on agent action.

Parameters:     

  * **action** \([_AgentAction_](https://python.langchain.com/api_reference/core/agents/langchain_core.agents.AgentAction.html#langchain_core.agents.AgentAction "langchain_core.agents.AgentAction")\) â€“ The agent action.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_agent\_finish\(

    _finish : [AgentFinish](https://python.langchain.com/api_reference/core/agents/langchain_core.agents.AgentFinish.html#langchain_core.agents.AgentFinish "langchain_core.agents.AgentFinish")_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run on the agent end.

Parameters:     

  * **finish** \([_AgentFinish_](https://python.langchain.com/api_reference/core/agents/langchain_core.agents.AgentFinish.html#langchain_core.agents.AgentFinish "langchain_core.agents.AgentFinish")\) â€“ The agent finish.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_chain\_end\(

    _outputs : dict\[str, Any\]_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run when chain ends running.

Parameters:     

  * **outputs** \(_dict_ _\[__str_ _,__Any_ _\]_\) â€“ The outputs of the chain.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_chain\_error\(

    _error : BaseException_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run when chain errors.

Parameters:     

  * **error** \(_BaseException_\) â€“ The error that occurred.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_chain\_start\(

    _serialized : dict\[str, Any\]_,     _inputs : dict\[str, Any\]_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _tags : list\[str\] | None = None_,     _metadata : dict\[str, Any\] | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run when a chain starts running.

Parameters:     

  * **serialized** \(_dict_ _\[__str_ _,__Any_ _\]_\) â€“ The serialized chain.

  * **inputs** \(_dict_ _\[__str_ _,__Any_ _\]_\) â€“ The inputs.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **tags** \(_Optional_ _\[__list_ _\[__str_ _\]__\]_\) â€“ The tags.

  * **metadata** \(_Optional_ _\[__dict_ _\[__str_ _,__Any_ _\]__\]_\) â€“ The metadata.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_chat\_model\_start\(

    _serialized : dict\[str, Any\]_,     _messages : list\[list\[[BaseMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage "langchain_core.messages.base.BaseMessage")\]\]_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _tags : list\[str\] | None = None_,     _metadata : dict\[str, Any\] | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run when a chat model starts running.

**ATTENTION** : This method is called for chat models. If youâ€™re implementing a handler for a non-chat model, you should use `on_llm_start` instead.

Parameters:     

  * **serialized** \(_dict_ _\[__str_ _,__Any_ _\]_\) â€“ The serialized chat model.

  * **messages** \(_list_ _\[__list_ _\[_[_BaseMessage_](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage "langchain_core.messages.base.BaseMessage") _\]__\]_\) â€“ The messages.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **tags** \(_Optional_ _\[__list_ _\[__str_ _\]__\]_\) â€“ The tags.

  * **metadata** \(_Optional_ _\[__dict_ _\[__str_ _,__Any_ _\]__\]_\) â€“ The metadata.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_custom\_event\(

    _name : str_,     _data : Any_,     _\*_ ,     _run\_id : UUID_,     _tags : list\[str\] | None = None_,     _metadata : dict\[str, Any\] | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Override to define a handler for a custom event.

Parameters:     

  * **name** \(_str_\) â€“ The name of the custom event.

  * **data** \(_Any_\) â€“ The data for the custom event. Format will match the format specified by the user.

  * **run\_id** \(_UUID_\) â€“ The ID of the run.

  * **tags** \(_Optional_ _\[__list_ _\[__str_ _\]__\]_\) â€“ The tags associated with the custom event \(includes inherited tags\).

  * **metadata** \(_Optional_ _\[__dict_ _\[__str_ _,__Any_ _\]__\]_\) â€“ The metadata associated with the custom event \(includes inherited metadata\).

  * **kwargs** \(_Any_\)

Return type:     

Any

Added in version 0.2.15.

on\_llm\_end\(

    _response : [LLMResult](https://python.langchain.com/api_reference/core/outputs/langchain_core.outputs.llm_result.LLMResult.html#langchain_core.outputs.llm_result.LLMResult "langchain_core.outputs.llm_result.LLMResult")_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run when LLM ends running.

Parameters:     

  * **response** \([_LLMResult_](https://python.langchain.com/api_reference/core/outputs/langchain_core.outputs.llm_result.LLMResult.html#langchain_core.outputs.llm_result.LLMResult "langchain_core.outputs.llm_result.LLMResult")\) â€“ The response which was generated.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_llm\_error\(

    _error : BaseException_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run when LLM errors.

Parameters:     

  * **error** \(_BaseException_\) â€“ The error that occurred.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_llm\_new\_token\(

    _token : str_,     _\*_ ,     _chunk : [GenerationChunk](https://python.langchain.com/api_reference/core/outputs/langchain_core.outputs.generation.GenerationChunk.html#langchain_core.outputs.generation.GenerationChunk "langchain_core.outputs.generation.GenerationChunk") | [ChatGenerationChunk](https://python.langchain.com/api_reference/core/outputs/langchain_core.outputs.chat_generation.ChatGenerationChunk.html#langchain_core.outputs.chat_generation.ChatGenerationChunk "langchain_core.outputs.chat_generation.ChatGenerationChunk") | None = None_,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run on new LLM token. Only available when streaming is enabled.

Parameters:     

  * **token** \(_str_\) â€“ The new token.

  * **chunk** \([_GenerationChunk_](https://python.langchain.com/api_reference/core/outputs/langchain_core.outputs.generation.GenerationChunk.html#langchain_core.outputs.generation.GenerationChunk "langchain_core.outputs.generation.GenerationChunk") _|_[_ChatGenerationChunk_](https://python.langchain.com/api_reference/core/outputs/langchain_core.outputs.chat_generation.ChatGenerationChunk.html#langchain_core.outputs.chat_generation.ChatGenerationChunk "langchain_core.outputs.chat_generation.ChatGenerationChunk")\) â€“ The new generated chunk, containing content and other information.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_llm\_start\(

    _serialized : dict\[str, Any\]_,     _prompts : list\[str\]_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _tags : list\[str\] | None = None_,     _metadata : dict\[str, Any\] | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run when LLM starts running.

Attention

This method is called for non-chat models \(regular LLMs\). If youâ€™re implementing a handler for a chat model, you should use `on_chat_model_start` instead.

Parameters:     

  * **serialized** \(_dict_ _\[__str_ _,__Any_ _\]_\) â€“ The serialized LLM.

  * **prompts** \(_list_ _\[__str_ _\]_\) â€“ The prompts.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **tags** \(_Optional_ _\[__list_ _\[__str_ _\]__\]_\) â€“ The tags.

  * **metadata** \(_Optional_ _\[__dict_ _\[__str_ _,__Any_ _\]__\]_\) â€“ The metadata.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_retriever\_end\(

    _documents : Sequence\[[Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document "langchain_core.documents.base.Document")\]_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run when Retriever ends running.

Parameters:     

  * **documents** \(_Sequence_ _\[_[_Document_](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document "langchain_core.documents.base.Document") _\]_\) â€“ The documents retrieved.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_retriever\_error\(

    _error : BaseException_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run when Retriever errors.

Parameters:     

  * **error** \(_BaseException_\) â€“ The error that occurred.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_retriever\_start\(

    _serialized : dict\[str, Any\]_,     _query : str_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _tags : list\[str\] | None = None_,     _metadata : dict\[str, Any\] | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run when the Retriever starts running.

Parameters:     

  * **serialized** \(_dict_ _\[__str_ _,__Any_ _\]_\) â€“ The serialized Retriever.

  * **query** \(_str_\) â€“ The query.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **tags** \(_Optional_ _\[__list_ _\[__str_ _\]__\]_\) â€“ The tags.

  * **metadata** \(_Optional_ _\[__dict_ _\[__str_ _,__Any_ _\]__\]_\) â€“ The metadata.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_retry\(

    _retry\_state : RetryCallState_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run on a retry event.

Parameters:     

  * **retry\_state** \(_RetryCallState_\) â€“ The retry state.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_text\(

    _text : str_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run on an arbitrary text.

Parameters:     

  * **text** \(_str_\) â€“ The text.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_tool\_end\(

    _output : Any_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run when the tool ends running.

Parameters:     

  * **output** \(_Any_\) â€“ The output of the tool.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_tool\_error\(

    _error : BaseException_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run when tool errors.

Parameters:     

  * **error** \(_BaseException_\) â€“ The error that occurred.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_tool\_start\(

    _serialized : dict\[str, Any\]_,     _input\_str : str_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _tags : list\[str\] | None = None_,     _metadata : dict\[str, Any\] | None = None_,     _inputs : dict\[str, Any\] | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run when the tool starts running.

Parameters:     

  * **serialized** \(_dict_ _\[__str_ _,__Any_ _\]_\) â€“ The serialized tool.

  * **input\_str** \(_str_\) â€“ The input string.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **tags** \(_Optional_ _\[__list_ _\[__str_ _\]__\]_\) â€“ The tags.

  * **metadata** \(_Optional_ _\[__dict_ _\[__str_ _,__Any_ _\]__\]_\) â€“ The metadata.

  * **inputs** \(_Optional_ _\[__dict_ _\[__str_ _,__Any_ _\]__\]_\) â€“ The inputs.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

Examples using WhyLabsCallbackHandler

  * [WhyLabs](https://python.langchain.com/docs/integrations/providers/whylabs_profiling/)

__On this page   *[\*]: Keyword-only parameters separator (PEP 3102)