# langchain.callbacks.streaming_aiter â€” ðŸ¦œðŸ”— LangChain  documentation

**URL:** https://python.langchain.com/api_reference/_modules/langchain/callbacks/streaming_aiter.html
**Word Count:** 114
**Links Count:** 19
**Scraped:** 2025-07-21 08:26:28
**Status:** completed

---

# Source code for langchain.callbacks.streaming\_aiter               from __future__ import annotations          import asyncio     from collections.abc import AsyncIterator     from typing import Any, Literal, Union, cast          from langchain_core.callbacks import AsyncCallbackHandler     from langchain_core.outputs import LLMResult          # TODO If used by two LLM runs in parallel this won't work as expected                              [[docs]](https://python.langchain.com/api_reference/langchain/callbacks/langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.html#langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler)     class AsyncIteratorCallbackHandler(AsyncCallbackHandler):         """Callback handler that returns an async iterator."""              queue: asyncio.Queue[str]              done: asyncio.Event              @property         def always_verbose(self) -> bool:             return True                         [[docs]](https://python.langchain.com/api_reference/langchain/callbacks/langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.html#langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.__init__)         def __init__(self) -> None:             self.queue = asyncio.Queue()             self.done = asyncio.Event()                                        [[docs]](https://python.langchain.com/api_reference/langchain/callbacks/langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.html#langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.on_llm_start)         async def on_llm_start(             self,             serialized: dict[str, Any],             prompts: list[str],             **kwargs: Any,         ) -> None:             # If two calls are made in a row, this resets the state             self.done.clear()                                        [[docs]](https://python.langchain.com/api_reference/langchain/callbacks/langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.html#langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.on_llm_new_token)         async def on_llm_new_token(self, token: str, **kwargs: Any) -> None:             if token is not None and token != "":                 self.queue.put_nowait(token)                                        [[docs]](https://python.langchain.com/api_reference/langchain/callbacks/langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.html#langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.on_llm_end)         async def on_llm_end(self, response: LLMResult, **kwargs: Any) -> None:             self.done.set()                                        [[docs]](https://python.langchain.com/api_reference/langchain/callbacks/langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.html#langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.on_llm_error)         async def on_llm_error(self, error: BaseException, **kwargs: Any) -> None:             self.done.set()                             # TODO implement the other methods                         [[docs]](https://python.langchain.com/api_reference/langchain/callbacks/langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.html#langchain.callbacks.streaming_aiter.AsyncIteratorCallbackHandler.aiter)         async def aiter(self) -> AsyncIterator[str]:             while not self.queue.empty() or not self.done.is_set():                 # Wait for the next token in the queue,                 # but stop waiting if the done event is set                 done, other = await asyncio.wait(                     [                         # NOTE: If you add other tasks here, update the code below,                         # which assumes each set has exactly one task each                         asyncio.ensure_future(self.queue.get()),                         asyncio.ensure_future(self.done.wait()),                     ],                     return_when=asyncio.FIRST_COMPLETED,                 )                      # Cancel the other task                 if other:                     other.pop().cancel()                      # Extract the value of the first completed task                 token_or_done = cast(Union[str, Literal[True]], done.pop().result())                      # If the extracted value is the boolean True, the done event was set                 if token_or_done is True:                     break                      # Otherwise, the extracted value is a token, which we yield                 yield token_or_done