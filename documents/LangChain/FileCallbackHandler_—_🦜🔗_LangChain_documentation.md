# FileCallbackHandler â€” ðŸ¦œðŸ”— LangChain  documentation

**URL:** https://python.langchain.com/api_reference/core/callbacks/langchain_core.callbacks.file.FileCallbackHandler.html
**Word Count:** 1162
**Links Count:** 221
**Scraped:** 2025-07-21 07:54:02
**Status:** completed

---

# FileCallbackHandler\#

_class _langchain\_core.callbacks.file.FileCallbackHandler\(

    _filename : str_,     _mode : str = 'a'_,     _color : str | None = None_, \)[\[source\]](https://python.langchain.com/api_reference/_modules/langchain_core/callbacks/file.html#FileCallbackHandler)\#     

Callback Handler that writes to a file.

This handler supports both context manager usage \(recommended\) and direct instantiation \(deprecated\) for backwards compatibility.

Examples

Using as a context manager \(recommended\):               with FileCallbackHandler("output.txt") as handler:         # Use handler with your chain/agent         chain.invoke(inputs, config={"callbacks": [handler]})     

Direct instantiation \(deprecated\):               handler = FileCallbackHandler("output.txt")     # File remains open until handler is garbage collected     try:         chain.invoke(inputs, config={"callbacks": [handler]})     finally:         handler.close()  # Explicit cleanup recommended     

Parameters:     

  * **filename** \(_str_\) â€“ The file path to write to.

  * **mode** \(_str_\) â€“ The file open mode. Defaults to `'a'` \(append\).

  * **color** \(_Optional_ _\[__str_ _\]_\) â€“ Default color for text output. Defaults to `None`.

Note

When not used as a context manager, a deprecation warning will be issued on first use. The file will be opened immediately in `__init__` and closed in `__del__` or when `close()` is called explicitly.

Initialize the file callback handler.

Parameters:     

  * **filename** \(_str_\) â€“ Path to the output file.

  * **mode** \(_str_\) â€“ File open mode \(e.g., `'w'`, `'a'`, `'x'`\). Defaults to `'a'`.

  * **color** \(_Optional_ _\[__str_ _\]_\) â€“ Default text color for output. Defaults to `None`.

Attributes

`ignore_agent` | Whether to ignore agent callbacks.   ---|---   `ignore_chain` | Whether to ignore chain callbacks.   `ignore_chat_model` | Whether to ignore chat model callbacks.   `ignore_custom_event` | Ignore custom event.   `ignore_llm` | Whether to ignore LLM callbacks.   `ignore_retriever` | Whether to ignore retriever callbacks.   `ignore_retry` | Whether to ignore retry callbacks.   `raise_error` | Whether to raise an error if an exception occurs.   `run_inline` | Whether to run the callback inline.      Methods

`__init__`\(filename\[, mode, color\]\) | Initialize the file callback handler.   ---|---   `close`\(\) | Close the file if it's open.   `on_agent_action`\(action\[, color\]\) | Handle agent action by writing the action log.   `on_agent_finish`\(finish\[, color\]\) | Handle agent finish by writing the finish log.   `on_chain_end`\(outputs, \*\*kwargs\) | Print that we finished a chain.   `on_chain_error`\(error, \*, run\_id\[, parent\_run\_id\]\) | Run when chain errors.   `on_chain_start`\(serialized, inputs, \*\*kwargs\) | Print that we are entering a chain.   `on_chat_model_start`\(serialized, messages, \*, ...\) | Run when a chat model starts running.   `on_custom_event`\(name, data, \*, run\_id\[, ...\]\) | Override to define a handler for a custom event.   `on_llm_end`\(response, \*, run\_id\[, parent\_run\_id\]\) | Run when LLM ends running.   `on_llm_error`\(error, \*, run\_id\[, parent\_run\_id\]\) | Run when LLM errors.   `on_llm_new_token`\(token, \*\[, chunk, ...\]\) | Run on new LLM token.   `on_llm_start`\(serialized, prompts, \*, run\_id\) | Run when LLM starts running.   `on_retriever_end`\(documents, \*, run\_id\[, ...\]\) | Run when Retriever ends running.   `on_retriever_error`\(error, \*, run\_id\[, ...\]\) | Run when Retriever errors.   `on_retriever_start`\(serialized, query, \*, run\_id\) | Run when the Retriever starts running.   `on_retry`\(retry\_state, \*, run\_id\[, parent\_run\_id\]\) | Run on a retry event.   `on_text`\(text\[, color, end\]\) | Handle text output.   `on_tool_end`\(output\[, color, ...\]\) | Handle tool end by writing the output with optional prefixes.   `on_tool_error`\(error, \*, run\_id\[, parent\_run\_id\]\) | Run when tool errors.   `on_tool_start`\(serialized, input\_str, \*, run\_id\) | Run when the tool starts running.      \_\_init\_\_\(

    _filename : str_,     _mode : str = 'a'_,     _color : str | None = None_, \) â†’ None[\[source\]](https://python.langchain.com/api_reference/_modules/langchain_core/callbacks/file.html#FileCallbackHandler.__init__)\#     

Initialize the file callback handler.

Parameters:     

  * **filename** \(_str_\) â€“ Path to the output file.

  * **mode** \(_str_\) â€“ File open mode \(e.g., `'w'`, `'a'`, `'x'`\). Defaults to `'a'`.

  * **color** \(_str_ _|__None_\) â€“ Default text color for output. Defaults to `None`.

Return type:     

None

close\(\) â†’ None[\[source\]](https://python.langchain.com/api_reference/_modules/langchain_core/callbacks/file.html#FileCallbackHandler.close)\#     

Close the file if itâ€™s open.

This method is safe to call multiple times and will only close the file if itâ€™s currently open.

Return type:     

None

on\_agent\_action\(

    _action : [AgentAction](https://python.langchain.com/api_reference/core/agents/langchain_core.agents.AgentAction.html#langchain_core.agents.AgentAction "langchain_core.agents.AgentAction")_,     _color : str | None = None_,     _\*\* kwargs: Any_, \) â†’ Any[\[source\]](https://python.langchain.com/api_reference/_modules/langchain_core/callbacks/file.html#FileCallbackHandler.on_agent_action)\#     

Handle agent action by writing the action log.

Parameters:     

  * **action** \([_AgentAction_](https://python.langchain.com/api_reference/core/agents/langchain_core.agents.AgentAction.html#langchain_core.agents.AgentAction "langchain_core.agents.AgentAction")\) â€“ The agent action containing the log to write.

  * **color** \(_Optional_ _\[__str_ _\]_\) â€“ Color override for this specific output. If `None`, uses `self.color`.

  * **\*\*kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_agent\_finish\(

    _finish : [AgentFinish](https://python.langchain.com/api_reference/core/agents/langchain_core.agents.AgentFinish.html#langchain_core.agents.AgentFinish "langchain_core.agents.AgentFinish")_,     _color : str | None = None_,     _\*\* kwargs: Any_, \) â†’ None[\[source\]](https://python.langchain.com/api_reference/_modules/langchain_core/callbacks/file.html#FileCallbackHandler.on_agent_finish)\#     

Handle agent finish by writing the finish log.

Parameters:     

  * **finish** \([_AgentFinish_](https://python.langchain.com/api_reference/core/agents/langchain_core.agents.AgentFinish.html#langchain_core.agents.AgentFinish "langchain_core.agents.AgentFinish")\) â€“ The agent finish object containing the log to write.

  * **color** \(_Optional_ _\[__str_ _\]_\) â€“ Color override for this specific output. If `None`, uses `self.color`.

  * **\*\*kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

None

on\_chain\_end\(

    _outputs : dict\[str, Any\]_,     _\*\* kwargs: Any_, \) â†’ None[\[source\]](https://python.langchain.com/api_reference/_modules/langchain_core/callbacks/file.html#FileCallbackHandler.on_chain_end)\#     

Print that we finished a chain.

Parameters:     

  * **outputs** \(_dict_ _\[__str_ _,__Any_ _\]_\) â€“ The outputs of the chain.

  * **\*\*kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

None

on\_chain\_error\(

    _error : BaseException_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run when chain errors.

Parameters:     

  * **error** \(_BaseException_\) â€“ The error that occurred.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_chain\_start\(

    _serialized : dict\[str, Any\]_,     _inputs : dict\[str, Any\]_,     _\*\* kwargs: Any_, \) â†’ None[\[source\]](https://python.langchain.com/api_reference/_modules/langchain_core/callbacks/file.html#FileCallbackHandler.on_chain_start)\#     

Print that we are entering a chain.

Parameters:     

  * **serialized** \(_dict_ _\[__str_ _,__Any_ _\]_\) â€“ The serialized chain information.

  * **inputs** \(_dict_ _\[__str_ _,__Any_ _\]_\) â€“ The inputs to the chain.

  * **\*\*kwargs** \(_Any_\) â€“ Additional keyword arguments that may contain `'name'`.

Return type:     

None

on\_chat\_model\_start\(

    _serialized : dict\[str, Any\]_,     _messages : list\[list\[[BaseMessage](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage "langchain_core.messages.base.BaseMessage")\]\]_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _tags : list\[str\] | None = None_,     _metadata : dict\[str, Any\] | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run when a chat model starts running.

**ATTENTION** : This method is called for chat models. If youâ€™re implementing a handler for a non-chat model, you should use `on_llm_start` instead.

Parameters:     

  * **serialized** \(_dict_ _\[__str_ _,__Any_ _\]_\) â€“ The serialized chat model.

  * **messages** \(_list_ _\[__list_ _\[_[_BaseMessage_](https://python.langchain.com/api_reference/core/messages/langchain_core.messages.base.BaseMessage.html#langchain_core.messages.base.BaseMessage "langchain_core.messages.base.BaseMessage") _\]__\]_\) â€“ The messages.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **tags** \(_Optional_ _\[__list_ _\[__str_ _\]__\]_\) â€“ The tags.

  * **metadata** \(_Optional_ _\[__dict_ _\[__str_ _,__Any_ _\]__\]_\) â€“ The metadata.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_custom\_event\(

    _name : str_,     _data : Any_,     _\*_ ,     _run\_id : UUID_,     _tags : list\[str\] | None = None_,     _metadata : dict\[str, Any\] | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Override to define a handler for a custom event.

Parameters:     

  * **name** \(_str_\) â€“ The name of the custom event.

  * **data** \(_Any_\) â€“ The data for the custom event. Format will match the format specified by the user.

  * **run\_id** \(_UUID_\) â€“ The ID of the run.

  * **tags** \(_Optional_ _\[__list_ _\[__str_ _\]__\]_\) â€“ The tags associated with the custom event \(includes inherited tags\).

  * **metadata** \(_Optional_ _\[__dict_ _\[__str_ _,__Any_ _\]__\]_\) â€“ The metadata associated with the custom event \(includes inherited metadata\).

  * **kwargs** \(_Any_\)

Return type:     

Any

Added in version 0.2.15.

on\_llm\_end\(

    _response : [LLMResult](https://python.langchain.com/api_reference/core/outputs/langchain_core.outputs.llm_result.LLMResult.html#langchain_core.outputs.llm_result.LLMResult "langchain_core.outputs.llm_result.LLMResult")_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run when LLM ends running.

Parameters:     

  * **response** \([_LLMResult_](https://python.langchain.com/api_reference/core/outputs/langchain_core.outputs.llm_result.LLMResult.html#langchain_core.outputs.llm_result.LLMResult "langchain_core.outputs.llm_result.LLMResult")\) â€“ The response which was generated.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_llm\_error\(

    _error : BaseException_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run when LLM errors.

Parameters:     

  * **error** \(_BaseException_\) â€“ The error that occurred.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_llm\_new\_token\(

    _token : str_,     _\*_ ,     _chunk : [GenerationChunk](https://python.langchain.com/api_reference/core/outputs/langchain_core.outputs.generation.GenerationChunk.html#langchain_core.outputs.generation.GenerationChunk "langchain_core.outputs.generation.GenerationChunk") | [ChatGenerationChunk](https://python.langchain.com/api_reference/core/outputs/langchain_core.outputs.chat_generation.ChatGenerationChunk.html#langchain_core.outputs.chat_generation.ChatGenerationChunk "langchain_core.outputs.chat_generation.ChatGenerationChunk") | None = None_,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run on new LLM token. Only available when streaming is enabled.

Parameters:     

  * **token** \(_str_\) â€“ The new token.

  * **chunk** \([_GenerationChunk_](https://python.langchain.com/api_reference/core/outputs/langchain_core.outputs.generation.GenerationChunk.html#langchain_core.outputs.generation.GenerationChunk "langchain_core.outputs.generation.GenerationChunk") _|_[_ChatGenerationChunk_](https://python.langchain.com/api_reference/core/outputs/langchain_core.outputs.chat_generation.ChatGenerationChunk.html#langchain_core.outputs.chat_generation.ChatGenerationChunk "langchain_core.outputs.chat_generation.ChatGenerationChunk")\) â€“ The new generated chunk, containing content and other information.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_llm\_start\(

    _serialized : dict\[str, Any\]_,     _prompts : list\[str\]_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _tags : list\[str\] | None = None_,     _metadata : dict\[str, Any\] | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run when LLM starts running.

Attention

This method is called for non-chat models \(regular LLMs\). If youâ€™re implementing a handler for a chat model, you should use `on_chat_model_start` instead.

Parameters:     

  * **serialized** \(_dict_ _\[__str_ _,__Any_ _\]_\) â€“ The serialized LLM.

  * **prompts** \(_list_ _\[__str_ _\]_\) â€“ The prompts.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **tags** \(_Optional_ _\[__list_ _\[__str_ _\]__\]_\) â€“ The tags.

  * **metadata** \(_Optional_ _\[__dict_ _\[__str_ _,__Any_ _\]__\]_\) â€“ The metadata.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_retriever\_end\(

    _documents : Sequence\[[Document](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document "langchain_core.documents.base.Document")\]_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run when Retriever ends running.

Parameters:     

  * **documents** \(_Sequence_ _\[_[_Document_](https://python.langchain.com/api_reference/core/documents/langchain_core.documents.base.Document.html#langchain_core.documents.base.Document "langchain_core.documents.base.Document") _\]_\) â€“ The documents retrieved.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_retriever\_error\(

    _error : BaseException_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run when Retriever errors.

Parameters:     

  * **error** \(_BaseException_\) â€“ The error that occurred.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_retriever\_start\(

    _serialized : dict\[str, Any\]_,     _query : str_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _tags : list\[str\] | None = None_,     _metadata : dict\[str, Any\] | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run when the Retriever starts running.

Parameters:     

  * **serialized** \(_dict_ _\[__str_ _,__Any_ _\]_\) â€“ The serialized Retriever.

  * **query** \(_str_\) â€“ The query.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **tags** \(_Optional_ _\[__list_ _\[__str_ _\]__\]_\) â€“ The tags.

  * **metadata** \(_Optional_ _\[__dict_ _\[__str_ _,__Any_ _\]__\]_\) â€“ The metadata.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_retry\(

    _retry\_state : RetryCallState_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run on a retry event.

Parameters:     

  * **retry\_state** \(_RetryCallState_\) â€“ The retry state.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_text\(

    _text : str_,     _color : str | None = None_,     _end : str = ''_,     _\*\* kwargs: Any_, \) â†’ None[\[source\]](https://python.langchain.com/api_reference/_modules/langchain_core/callbacks/file.html#FileCallbackHandler.on_text)\#     

Handle text output.

Parameters:     

  * **text** \(_str_\) â€“ The text to write.

  * **color** \(_str_ _|__None_\) â€“ Color override for this specific output. If `None`, uses `self.color`.

  * **end** \(_str_\) â€“ String appended after the text. Defaults to `""`.

  * **\*\*kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

None

on\_tool\_end\(

    _output : str_,     _color : str | None = None_,     _observation\_prefix : str | None = None_,     _llm\_prefix : str | None = None_,     _\*\* kwargs: Any_, \) â†’ None[\[source\]](https://python.langchain.com/api_reference/_modules/langchain_core/callbacks/file.html#FileCallbackHandler.on_tool_end)\#     

Handle tool end by writing the output with optional prefixes.

Parameters:     

  * **output** \(_str_\) â€“ The tool output to write.

  * **color** \(_str_ _|__None_\) â€“ Color override for this specific output. If `None`, uses `self.color`.

  * **observation\_prefix** \(_str_ _|__None_\) â€“ Optional prefix to write before the output.

  * **llm\_prefix** \(_str_ _|__None_\) â€“ Optional prefix to write after the output.

  * **\*\*kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

None

on\_tool\_error\(

    _error : BaseException_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run when tool errors.

Parameters:     

  * **error** \(_BaseException_\) â€“ The error that occurred.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

on\_tool\_start\(

    _serialized : dict\[str, Any\]_,     _input\_str : str_,     _\*_ ,     _run\_id : UUID_,     _parent\_run\_id : UUID | None = None_,     _tags : list\[str\] | None = None_,     _metadata : dict\[str, Any\] | None = None_,     _inputs : dict\[str, Any\] | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run when the tool starts running.

Parameters:     

  * **serialized** \(_dict_ _\[__str_ _,__Any_ _\]_\) â€“ The serialized tool.

  * **input\_str** \(_str_\) â€“ The input string.

  * **run\_id** \(_UUID_\) â€“ The run ID. This is the ID of the current run.

  * **parent\_run\_id** \(_UUID_\) â€“ The parent run ID. This is the ID of the parent run.

  * **tags** \(_Optional_ _\[__list_ _\[__str_ _\]__\]_\) â€“ The tags.

  * **metadata** \(_Optional_ _\[__dict_ _\[__str_ _,__Any_ _\]__\]_\) â€“ The metadata.

  * **inputs** \(_Optional_ _\[__dict_ _\[__str_ _,__Any_ _\]__\]_\) â€“ The inputs.

  * **kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

Any

__On this page   *[\*]: Keyword-only parameters separator (PEP 3102)