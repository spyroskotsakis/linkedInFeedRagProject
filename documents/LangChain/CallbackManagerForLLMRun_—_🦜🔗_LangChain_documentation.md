# CallbackManagerForLLMRun â€” ðŸ¦œðŸ”— LangChain  documentation

**URL:** https://python.langchain.com/api_reference/core/callbacks/langchain_core.callbacks.manager.CallbackManagerForLLMRun.html
**Word Count:** 362
**Links Count:** 180
**Scraped:** 2025-07-21 07:55:55
**Status:** completed

---

# CallbackManagerForLLMRun\#

_class _langchain\_core.callbacks.manager.CallbackManagerForLLMRun\(

    _\*_ ,     _run\_id : UUID_,     _handlers : list\[[BaseCallbackHandler](https://python.langchain.com/api_reference/core/callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler "langchain_core.callbacks.base.BaseCallbackHandler")\]_,     _inheritable\_handlers : list\[[BaseCallbackHandler](https://python.langchain.com/api_reference/core/callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler "langchain_core.callbacks.base.BaseCallbackHandler")\]_,     _parent\_run\_id : UUID | None = None_,     _tags : list\[str\] | None = None_,     _inheritable\_tags : list\[str\] | None = None_,     _metadata : dict\[str, Any\] | None = None_,     _inheritable\_metadata : dict\[str, Any\] | None = None_, \)[\[source\]](https://python.langchain.com/api_reference/_modules/langchain_core/callbacks/manager.html#CallbackManagerForLLMRun)\#     

Callback manager for LLM run.

Initialize the run manager.

Parameters:     

  * **run\_id** \(_UUID_\) â€“ The ID of the run.

  * **handlers** \(_list_ _\[_[_BaseCallbackHandler_](https://python.langchain.com/api_reference/core/callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler "langchain_core.callbacks.base.BaseCallbackHandler") _\]_\) â€“ The list of handlers.

  * **inheritable\_handlers** \(_list_ _\[_[_BaseCallbackHandler_](https://python.langchain.com/api_reference/core/callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler "langchain_core.callbacks.base.BaseCallbackHandler") _\]_\) â€“ The list of inheritable handlers.

  * **parent\_run\_id** \(_UUID_ _,__optional_\) â€“ The ID of the parent run. Defaults to None.

  * **tags** \(_Optional_ _\[__list_ _\[__str_ _\]__\]_\) â€“ The list of tags. Defaults to None.

  * **inheritable\_tags** \(_Optional_ _\[__list_ _\[__str_ _\]__\]_\) â€“ The list of inheritable tags. Defaults to None.

  * **metadata** \(_Optional_ _\[__dict_ _\[__str_ _,__Any_ _\]__\]_\) â€“ The metadata. Defaults to None.

  * **inheritable\_metadata** \(_Optional_ _\[__dict_ _\[__str_ _,__Any_ _\]__\]_\) â€“ The inheritable metadata. Defaults to None.

Methods

`__init__`\(\*, run\_id, handlers, ...\[, ...\]\) | Initialize the run manager.   ---|---   `get_noop_manager`\(\) | Return a manager that doesn't perform any operations.   `on_custom_event`\(name, data, \*, run\_id\[, ...\]\) | Override to define a handler for a custom event.   `on_llm_end`\(response, \*\*kwargs\) | Run when LLM ends running.   `on_llm_error`\(error, \*\*kwargs\) | Run when LLM errors.   `on_llm_new_token`\(token, \*\[, chunk\]\) | Run when LLM generates a new token.   `on_retry`\(retry\_state, \*\*kwargs\) | Run when a retry is received.   `on_text`\(text, \*\*kwargs\) | Run when a text is received.      \_\_init\_\_\(

    _\*_ ,     _run\_id : UUID_,     _handlers : list\[[BaseCallbackHandler](https://python.langchain.com/api_reference/core/callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler "langchain_core.callbacks.base.BaseCallbackHandler")\]_,     _inheritable\_handlers : list\[[BaseCallbackHandler](https://python.langchain.com/api_reference/core/callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler "langchain_core.callbacks.base.BaseCallbackHandler")\]_,     _parent\_run\_id : UUID | None = None_,     _tags : list\[str\] | None = None_,     _inheritable\_tags : list\[str\] | None = None_,     _metadata : dict\[str, Any\] | None = None_,     _inheritable\_metadata : dict\[str, Any\] | None = None_, \) â†’ None\#     

Initialize the run manager.

Parameters:     

  * **run\_id** \(_UUID_\) â€“ The ID of the run.

  * **handlers** \(_list_ _\[_[_BaseCallbackHandler_](https://python.langchain.com/api_reference/core/callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler "langchain_core.callbacks.base.BaseCallbackHandler") _\]_\) â€“ The list of handlers.

  * **inheritable\_handlers** \(_list_ _\[_[_BaseCallbackHandler_](https://python.langchain.com/api_reference/core/callbacks/langchain_core.callbacks.base.BaseCallbackHandler.html#langchain_core.callbacks.base.BaseCallbackHandler "langchain_core.callbacks.base.BaseCallbackHandler") _\]_\) â€“ The list of inheritable handlers.

  * **parent\_run\_id** \(_UUID_ _,__optional_\) â€“ The ID of the parent run. Defaults to None.

  * **tags** \(_Optional_ _\[__list_ _\[__str_ _\]__\]_\) â€“ The list of tags. Defaults to None.

  * **inheritable\_tags** \(_Optional_ _\[__list_ _\[__str_ _\]__\]_\) â€“ The list of inheritable tags. Defaults to None.

  * **metadata** \(_Optional_ _\[__dict_ _\[__str_ _,__Any_ _\]__\]_\) â€“ The metadata. Defaults to None.

  * **inheritable\_metadata** \(_Optional_ _\[__dict_ _\[__str_ _,__Any_ _\]__\]_\) â€“ The inheritable metadata. Defaults to None.

Return type:     

None

_classmethod _get\_noop\_manager\(\) â†’ Self\#     

Return a manager that doesnâ€™t perform any operations.

Returns:     

The noop manager.

Return type:     

[BaseRunManager](https://python.langchain.com/api_reference/core/callbacks/langchain_core.callbacks.manager.BaseRunManager.html#langchain_core.callbacks.manager.BaseRunManager "langchain_core.callbacks.manager.BaseRunManager")

on\_custom\_event\(

    _name : str_,     _data : Any_,     _\*_ ,     _run\_id : UUID_,     _tags : list\[str\] | None = None_,     _metadata : dict\[str, Any\] | None = None_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Override to define a handler for a custom event.

Parameters:     

  * **name** \(_str_\) â€“ The name of the custom event.

  * **data** \(_Any_\) â€“ The data for the custom event. Format will match the format specified by the user.

  * **run\_id** \(_UUID_\) â€“ The ID of the run.

  * **tags** \(_Optional_ _\[__list_ _\[__str_ _\]__\]_\) â€“ The tags associated with the custom event \(includes inherited tags\).

  * **metadata** \(_Optional_ _\[__dict_ _\[__str_ _,__Any_ _\]__\]_\) â€“ The metadata associated with the custom event \(includes inherited metadata\).

  * **kwargs** \(_Any_\)

Return type:     

Any

Added in version 0.2.15.

on\_llm\_end\(

    _response : [LLMResult](https://python.langchain.com/api_reference/core/outputs/langchain_core.outputs.llm_result.LLMResult.html#langchain_core.outputs.llm_result.LLMResult "langchain_core.outputs.llm_result.LLMResult")_,     _\*\* kwargs: Any_, \) â†’ None[\[source\]](https://python.langchain.com/api_reference/_modules/langchain_core/callbacks/manager.html#CallbackManagerForLLMRun.on_llm_end)\#     

Run when LLM ends running.

Parameters:     

  * **response** \([_LLMResult_](https://python.langchain.com/api_reference/core/outputs/langchain_core.outputs.llm_result.LLMResult.html#langchain_core.outputs.llm_result.LLMResult "langchain_core.outputs.llm_result.LLMResult")\) â€“ The LLM result.

  * **\*\*kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

None

on\_llm\_error\(

    _error : BaseException_,     _\*\* kwargs: Any_, \) â†’ None[\[source\]](https://python.langchain.com/api_reference/_modules/langchain_core/callbacks/manager.html#CallbackManagerForLLMRun.on_llm_error)\#     

Run when LLM errors.

Parameters:     

  * **error** \(_Exception_ _or_ _KeyboardInterrupt_\) â€“ The error.

  * **kwargs** \(_Any_\) â€“ 

Additional keyword arguments. \- response \(LLMResult\): The response which was generated before

> the error occurred.

Return type:     

None

on\_llm\_new\_token\(

    _token : str_,     _\*_ ,     _chunk : [GenerationChunk](https://python.langchain.com/api_reference/core/outputs/langchain_core.outputs.generation.GenerationChunk.html#langchain_core.outputs.generation.GenerationChunk "langchain_core.outputs.generation.GenerationChunk") | [ChatGenerationChunk](https://python.langchain.com/api_reference/core/outputs/langchain_core.outputs.chat_generation.ChatGenerationChunk.html#langchain_core.outputs.chat_generation.ChatGenerationChunk "langchain_core.outputs.chat_generation.ChatGenerationChunk") | None = None_,     _\*\* kwargs: Any_, \) â†’ None[\[source\]](https://python.langchain.com/api_reference/_modules/langchain_core/callbacks/manager.html#CallbackManagerForLLMRun.on_llm_new_token)\#     

Run when LLM generates a new token.

Parameters:     

  * **token** \(_str_\) â€“ The new token.

  * **chunk** \(_Optional_ _\[__Union_ _\[_[_GenerationChunk_](https://python.langchain.com/api_reference/core/outputs/langchain_core.outputs.generation.GenerationChunk.html#langchain_core.outputs.generation.GenerationChunk "langchain_core.outputs.generation.GenerationChunk") _,_[_ChatGenerationChunk_](https://python.langchain.com/api_reference/core/outputs/langchain_core.outputs.chat_generation.ChatGenerationChunk.html#langchain_core.outputs.chat_generation.ChatGenerationChunk "langchain_core.outputs.chat_generation.ChatGenerationChunk") _\]__\]__,__optional_\) â€“ The chunk. Defaults to None.

  * **\*\*kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

None

on\_retry\(

    _retry\_state : RetryCallState_,     _\*\* kwargs: Any_, \) â†’ None\#     

Run when a retry is received.

Parameters:     

  * **retry\_state** \(_RetryCallState_\) â€“ The retry state.

  * **\*\*kwargs** \(_Any_\) â€“ Additional keyword arguments.

Return type:     

None

on\_text\(

    _text : str_,     _\*\* kwargs: Any_, \) â†’ Any\#     

Run when a text is received.

Parameters:     

  * **text** \(_str_\) â€“ The received text.

  * **\*\*kwargs** \(_Any_\) â€“ Additional keyword arguments.

Returns:     

The result of the callback.

Return type:     

Any

Examples using CallbackManagerForLLMRun

  * [How to create a custom LLM class](https://python.langchain.com/docs/how_to/custom_llm/)

  * [How to create a custom chat model class](https://python.langchain.com/docs/how_to/custom_chat_model/)

__On this page   *[\*]: Keyword-only parameters separator (PEP 3102)