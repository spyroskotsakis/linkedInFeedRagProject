# language_models ‚Äî ü¶úüîó LangChain  documentation

**URL:** https://python.langchain.com/api_reference/core/language_models.html
**Word Count:** 383
**Links Count:** 140
**Scraped:** 2025-07-21 07:53:06
**Status:** completed

---

# `language_models`\#

Language models.

**Language Model** is a type of model that can generate text or complete text prompts.

LangChain has two main classes to work with language models: **Chat Models** and ‚Äúold-fashioned‚Äù **LLMs**.

**Chat Models**

Language models that use a sequence of messages as inputs and return chat messages as outputs \(as opposed to using plain text\). These are traditionally newer models \( older models are generally LLMs, see below\). Chat models support the assignment of distinct roles to conversation messages, helping to distinguish messages from the AI, users, and instructions such as system messages.

The key abstraction for chat models is BaseChatModel. Implementations should inherit from this class. Please see LangChain how-to guides with more information on how to implement a custom chat model.

To implement a custom Chat Model, inherit from BaseChatModel. See the following guide for more information on how to implement a custom Chat Model:

<https://python.langchain.com/docs/how_to/custom_chat_model/>

**LLMs**

Language models that takes a string as input and returns a string. These are traditionally older models \(newer models generally are Chat Models, see below\).

Although the underlying models are string in, string out, the LangChain wrappers also allow these models to take messages as input. This gives them the same interface as Chat Models. When messages are passed in as input, they will be formatted into a string under the hood before being passed to the underlying model.

To implement a custom LLM, inherit from BaseLLM or LLM. Please see the following guide for more information on how to implement a custom LLM:

<https://python.langchain.com/docs/how_to/custom_llm/>

**Classes**

[`language_models.base.BaseLanguageModel`](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.base.BaseLanguageModel.html#langchain_core.language_models.base.BaseLanguageModel "langchain_core.language_models.base.BaseLanguageModel") | Abstract base class for interfacing with language models.   ---|---   `language_models.base.BaseLanguageModel[str]` | Abstract base class for interfacing with language models.   [`language_models.base.LangSmithParams`](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.base.LangSmithParams.html#langchain_core.language_models.base.LangSmithParams "langchain_core.language_models.base.LangSmithParams") | LangSmith parameters for tracing.   [`language_models.chat_models.BaseChatModel`](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.chat_models.BaseChatModel.html#langchain_core.language_models.chat_models.BaseChatModel "langchain_core.language_models.chat_models.BaseChatModel") | Base class for chat models.   [`language_models.chat_models.SimpleChatModel`](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.chat_models.SimpleChatModel.html#langchain_core.language_models.chat_models.SimpleChatModel "langchain_core.language_models.chat_models.SimpleChatModel") | Simplified implementation for a chat model to inherit from.   [`language_models.fake.FakeListLLM`](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.fake.FakeListLLM.html#langchain_core.language_models.fake.FakeListLLM "langchain_core.language_models.fake.FakeListLLM") | Fake LLM for testing purposes.   [`language_models.fake.FakeListLLMError`](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.fake.FakeListLLMError.html#langchain_core.language_models.fake.FakeListLLMError "langchain_core.language_models.fake.FakeListLLMError") | Fake error for testing purposes.   [`language_models.fake.FakeStreamingListLLM`](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.fake.FakeStreamingListLLM.html#langchain_core.language_models.fake.FakeStreamingListLLM "langchain_core.language_models.fake.FakeStreamingListLLM") | Fake streaming list LLM for testing purposes.   [`language_models.fake_chat_models.FakeChatModel`](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.fake_chat_models.FakeChatModel.html#langchain_core.language_models.fake_chat_models.FakeChatModel "langchain_core.language_models.fake_chat_models.FakeChatModel") | Fake Chat Model wrapper for testing purposes.   [`language_models.fake_chat_models.FakeListChatModel`](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.fake_chat_models.FakeListChatModel.html#langchain_core.language_models.fake_chat_models.FakeListChatModel "langchain_core.language_models.fake_chat_models.FakeListChatModel") | Fake ChatModel for testing purposes.   [`language_models.fake_chat_models.FakeListChatModelError`](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.fake_chat_models.FakeListChatModelError.html#langchain_core.language_models.fake_chat_models.FakeListChatModelError "langchain_core.language_models.fake_chat_models.FakeListChatModelError") | Fake error for testing purposes.   [`language_models.fake_chat_models.FakeMessagesListChatModel`](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.fake_chat_models.FakeMessagesListChatModel.html#langchain_core.language_models.fake_chat_models.FakeMessagesListChatModel "langchain_core.language_models.fake_chat_models.FakeMessagesListChatModel") | Fake ChatModel for testing purposes.   [`language_models.fake_chat_models.GenericFakeChatModel`](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.fake_chat_models.GenericFakeChatModel.html#langchain_core.language_models.fake_chat_models.GenericFakeChatModel "langchain_core.language_models.fake_chat_models.GenericFakeChatModel") | Generic fake chat model that can be used to test the chat model interface.   [`language_models.fake_chat_models.ParrotFakeChatModel`](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.fake_chat_models.ParrotFakeChatModel.html#langchain_core.language_models.fake_chat_models.ParrotFakeChatModel "langchain_core.language_models.fake_chat_models.ParrotFakeChatModel") | Generic fake chat model that can be used to test the chat model interface.   [`language_models.llms.BaseLLM`](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.llms.BaseLLM.html#langchain_core.language_models.llms.BaseLLM "langchain_core.language_models.llms.BaseLLM") | Base LLM abstract interface.   [`language_models.llms.LLM`](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.llms.LLM.html#langchain_core.language_models.llms.LLM "langchain_core.language_models.llms.LLM") | Simple interface for implementing a custom LLM.      **Functions**

[`language_models.chat_models.agenerate_from_stream`](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.chat_models.agenerate_from_stream.html#langchain_core.language_models.chat_models.agenerate_from_stream "langchain_core.language_models.chat_models.agenerate_from_stream")\(stream\) | Async generate from a stream.   ---|---   [`language_models.chat_models.generate_from_stream`](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.chat_models.generate_from_stream.html#langchain_core.language_models.chat_models.generate_from_stream "langchain_core.language_models.chat_models.generate_from_stream")\(stream\) | Generate from a stream.   [`language_models.llms.aget_prompts`](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.llms.aget_prompts.html#langchain_core.language_models.llms.aget_prompts "langchain_core.language_models.llms.aget_prompts")\(params, ...\) | Get prompts that are already cached.   [`language_models.llms.aupdate_cache`](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.llms.aupdate_cache.html#langchain_core.language_models.llms.aupdate_cache "langchain_core.language_models.llms.aupdate_cache")\(cache, ...\) | Update the cache and get the LLM output.   [`language_models.llms.create_base_retry_decorator`](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.llms.create_base_retry_decorator.html#langchain_core.language_models.llms.create_base_retry_decorator "langchain_core.language_models.llms.create_base_retry_decorator")\(...\) | Create a retry decorator for a given LLM and provided a list of error types.   [`language_models.llms.get_prompts`](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.llms.get_prompts.html#langchain_core.language_models.llms.get_prompts "langchain_core.language_models.llms.get_prompts")\(params, prompts\) | Get prompts that are already cached.   [`language_models.llms.update_cache`](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.llms.update_cache.html#langchain_core.language_models.llms.update_cache "langchain_core.language_models.llms.update_cache")\(cache, ...\) | Update the cache and get the LLM output.