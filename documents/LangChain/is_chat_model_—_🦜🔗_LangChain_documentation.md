# is_chat_model â€” ðŸ¦œðŸ”— LangChain  documentation

**URL:** https://python.langchain.com/api_reference/langchain/chains/langchain.chains.prompt_selector.is_chat_model.html
**Word Count:** 31
**Links Count:** 190
**Scraped:** 2025-07-21 07:49:32
**Status:** completed

---

# is\_chat\_model\#

langchain.chains.prompt\_selector.is\_chat\_model\(

    _llm : [BaseLanguageModel](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.base.BaseLanguageModel.html#langchain_core.language_models.base.BaseLanguageModel "langchain_core.language_models.base.BaseLanguageModel")_, \) â†’ bool[\[source\]](https://python.langchain.com/api_reference/_modules/langchain/chains/prompt_selector.html#is_chat_model)\#     

Check if the language model is a chat model.

Parameters:     

**llm** \([_BaseLanguageModel_](https://python.langchain.com/api_reference/core/language_models/langchain_core.language_models.base.BaseLanguageModel.html#langchain_core.language_models.base.BaseLanguageModel "langchain_core.language_models.base.BaseLanguageModel")\) â€“ Language model to check.

Returns:     

True if the language model is a BaseChatModel model, False otherwise.

Return type:     

bool

__On this page