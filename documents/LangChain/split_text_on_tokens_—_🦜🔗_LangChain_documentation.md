# split_text_on_tokens â€” ðŸ¦œðŸ”— LangChain  documentation

**URL:** https://python.langchain.com/api_reference/text_splitters/base/langchain_text_splitters.base.split_text_on_tokens.html
**Word Count:** 15
**Links Count:** 86
**Scraped:** 2025-07-21 07:58:09
**Status:** completed

---

# split\_text\_on\_tokens\#

langchain\_text\_splitters.base.split\_text\_on\_tokens\(

    _\*_ ,     _text : str_,     _tokenizer : [Tokenizer](https://python.langchain.com/api_reference/text_splitters/base/langchain_text_splitters.base.Tokenizer.html#langchain_text_splitters.base.Tokenizer "langchain_text_splitters.base.Tokenizer")_, \) â†’ list\[str\][\[source\]](https://python.langchain.com/api_reference/_modules/langchain_text_splitters/base.html#split_text_on_tokens)\#     

Split incoming text and return chunks using tokenizer.

Parameters:     

  * **text** \(_str_\)

  * **tokenizer** \([_Tokenizer_](https://python.langchain.com/api_reference/text_splitters/base/langchain_text_splitters.base.Tokenizer.html#langchain_text_splitters.base.Tokenizer "langchain_text_splitters.base.Tokenizer")\)

Return type:     

list\[str\]

__On this page   *[\*]: Keyword-only parameters separator (PEP 3102)